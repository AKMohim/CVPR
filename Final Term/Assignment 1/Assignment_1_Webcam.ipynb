{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import io"
      ],
      "metadata": {
        "id": "O6UYIxeF-HOq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVMkCDbS7K4a",
        "outputId": "ef79e904-11b1-477c-d3c2-89db3ee4669f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IsKCdLx56qW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b66ca8-e3f8-4b4a-b19c-9a1348e3079a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'compile_metrics']\n"
          ]
        }
      ],
      "source": [
        "model = load_model('/content/drive/MyDrive/dataset/face_recognition_model.keras')\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model.metrics_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1FJHNqSWGKvP",
        "outputId": "66fff9ff-5a57-47a0-9358-618e294d1af4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method TensorFlowTrainer.evaluate of <Sequential name=sequential, built=True>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.backend.tensorflow.trainer.TensorFlowTrainer.evaluate</b><br/>def evaluate(x=None, y=None, batch_size=None, verbose=&#x27;auto&#x27;, sample_weight=None, steps=None, callbacks=None, return_dict=False, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py</a>Returns the loss value &amp; metrics values for the model in test mode.\n",
              "\n",
              "Computation is done in batches (see the `batch_size` arg.)\n",
              "\n",
              "Args:\n",
              "    x: Input data. It can be:\n",
              "        - A NumPy array (or array-like), or a list of arrays\n",
              "        (in case the model has multiple inputs).\n",
              "        - A backend-native tensor, or a list of tensors\n",
              "        (in case the model has multiple inputs).\n",
              "        - A dict mapping input names to the corresponding array/tensors,\n",
              "        if the model has named inputs.\n",
              "        - A `keras.utils.PyDataset` returning `(inputs, targets)` or\n",
              "        `(inputs, targets, sample_weights)`.\n",
              "        - A `tf.data.Dataset` yielding `(inputs, targets)` or\n",
              "        `(inputs, targets, sample_weights)`.\n",
              "        - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`\n",
              "        or `(inputs, targets, sample_weights)`.\n",
              "        - A Python generator function yielding `(inputs, targets)` or\n",
              "        `(inputs, targets, sample_weights)`.\n",
              "    y: Target data. Like the input data `x`, it can be either NumPy\n",
              "        array(s) or backend-native tensor(s). If `x` is a\n",
              "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
              "        `torch.utils.data.DataLoader` or a Python generator function,\n",
              "        `y` should not be specified since targets will be obtained from\n",
              "        `x`.\n",
              "    batch_size: Integer or `None`.\n",
              "        Number of samples per batch of computation.\n",
              "        If unspecified, `batch_size` will default to 32.\n",
              "        Do not specify the `batch_size` if your input data `x` is a\n",
              "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
              "        `torch.utils.data.DataLoader` or Python generator function\n",
              "        since they generate batches.\n",
              "    verbose: `&quot;auto&quot;`, 0, 1, or 2. Verbosity mode.\n",
              "        0 = silent, 1 = progress bar, 2 = single line.\n",
              "        `&quot;auto&quot;` becomes 1 for most cases.\n",
              "        Note that the progress bar is not\n",
              "        particularly useful when logged to a file, so `verbose=2` is\n",
              "        recommended when not running interactively\n",
              "        (e.g. in a production environment). Defaults to `&quot;auto&quot;`.\n",
              "    sample_weight: Optional NumPy array or tensor of weights for\n",
              "        the training samples, used for weighting the loss function\n",
              "        (during training only). You can either pass a flat (1D)\n",
              "        NumPy array or tensor with the same length as the input samples\n",
              "        (1:1 mapping between weights and samples), or in the case of\n",
              "        temporal data, you can pass a 2D NumPy array or tensor with\n",
              "        shape `(samples, sequence_length)` to apply a different weight\n",
              "        to every timestep of every sample.\n",
              "        This argument is not supported when `x` is a\n",
              "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
              "        `torch.utils.data.DataLoader` or Python generator function.\n",
              "        Instead, provide `sample_weights` as the third element of `x`.\n",
              "        Note that sample weighting does not apply to metrics specified\n",
              "        via the `metrics` argument in `compile()`. To apply sample\n",
              "        weighting to your metrics, you can specify them via the\n",
              "        `weighted_metrics` in `compile()` instead.\n",
              "    steps: Integer or `None`.\n",
              "        Total number of steps (batches of samples) to draw before\n",
              "        declaring the evaluation round finished. If `steps` is `None`,\n",
              "        it will run until `x` is exhausted. In the case of an infinitely\n",
              "        repeating dataset, it will run indefinitely.\n",
              "    callbacks: List of `keras.callbacks.Callback` instances.\n",
              "        List of callbacks to apply during evaluation.\n",
              "    return_dict: If `True`, loss and metric results are returned as a\n",
              "        dict, with each key being the name of the metric.\n",
              "        If `False`, they are returned as a list.\n",
              "\n",
              "Returns:\n",
              "    Scalar test loss (if the model has a single output and no metrics)\n",
              "    or list of scalars (if the model has multiple outputs\n",
              "    and/or metrics). The attribute `model.metrics_names` will give you\n",
              "    the display labels for the scalar outputs.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 427);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "print(\"Model input shape:\", model.input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "vhyZwyZV7nqc",
        "outputId": "245783c4-5754-4c7e-ba3d-cbcb32d37124"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │       \u001b[38;5;34m7,037,504\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m262,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m260\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,343,108\u001b[0m (28.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,343,108</span> (28.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m304,708\u001b[0m (1.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">304,708</span> (1.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,038,400\u001b[0m (26.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,038,400</span> (26.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input shape: (None, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Camera** **ON**"
      ],
      "metadata": {
        "id": "9-5X0wi_AH1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL.Image\n",
        "import io\n",
        "import pickle\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "pickle_in = open(\"/content/drive/MyDrive/dataset/data.pkl\", \"rb\")\n",
        "data_load = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"/content/drive/MyDrive/dataset/label_encoder.pkl\", \"rb\")\n",
        "label_encoder= pickle.load(pickle_in)\n",
        "\n",
        "with open('/content/drive/MyDrive/dataset/categories.pkl', 'rb') as f:\n",
        "    class_labels = pickle.load(f)\n",
        "\n",
        "print(\"Loaded Class Labels:\", class_labels)\n",
        "print(\"Loaded Labels:\", class_labels)\n",
        "\n",
        "\n",
        "def preprocess_face(face, target_shape):\n",
        "    face_resized = cv2.resize(face, (target_shape[1], target_shape[2]))\n",
        "    face_normalized = face_resized / 255.0\n",
        "    face_array = np.expand_dims(face_normalized, axis=0)\n",
        "    if len(model.input_shape) == 2:\n",
        "        face_array = face_array.reshape((1, -1))\n",
        "    return face_array\n",
        "\n",
        "def predict_label(face_array):\n",
        "    predictions = model.predict(face_array, verbose=0)\n",
        "    confidence = np.max(predictions)\n",
        "    label_index = np.argmax(predictions)\n",
        "\n",
        "    return label_index, confidence\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "def bbox_to_bytes(bbox_array):\n",
        "\n",
        "    if len(bbox_array.shape) == 3 and bbox_array.shape[2] != 4:\n",
        "        bbox_array = cv2.cvtColor(bbox_array, cv2.COLOR_BGR2BGRA)\n",
        "\n",
        "    bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "\n",
        "    iobuf = io.BytesIO()\n",
        "\n",
        "    bbox_PIL.save(iobuf, format='PNG')\n",
        "\n",
        "    bbox_bytes = 'data:image/png;base64,{}'.format(str(b64encode(iobuf.getvalue()), 'utf-8'))\n",
        "    return bbox_bytes\n",
        "\n",
        "def video_stream():\n",
        "    js = Javascript('''\n",
        "        var video;\n",
        "        var div = null;\n",
        "        var stream;\n",
        "        var captureCanvas;\n",
        "        var imgElement;\n",
        "        var labelElement;\n",
        "\n",
        "        var pendingResolve = null;\n",
        "        var shutdown = false;\n",
        "\n",
        "        function removeDom() {\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            video.remove();\n",
        "            div.remove();\n",
        "            video = null;\n",
        "            div = null;\n",
        "            stream = null;\n",
        "            imgElement = null;\n",
        "            captureCanvas = null;\n",
        "            labelElement = null;\n",
        "        }\n",
        "\n",
        "        function onAnimationFrame() {\n",
        "            if (!shutdown) {\n",
        "                window.requestAnimationFrame(onAnimationFrame);\n",
        "            }\n",
        "            if (pendingResolve) {\n",
        "                var result = \"\";\n",
        "                if (!shutdown) {\n",
        "                    captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "                    result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
        "                }\n",
        "                var lp = pendingResolve;\n",
        "                pendingResolve = null;\n",
        "                lp(result);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        async function createDom() {\n",
        "            if (div !== null) {\n",
        "                return stream;\n",
        "            }\n",
        "\n",
        "            div = document.createElement('div');\n",
        "            div.style.border = '2px solid black';\n",
        "            div.style.padding = '3px';\n",
        "            div.style.width = '100%';\n",
        "            div.style.height = '100%';\n",
        "            div.style.maxWidth = '600px';\n",
        "            document.body.appendChild(div);\n",
        "\n",
        "            const modelOut = document.createElement('div');\n",
        "            modelOut.innerHTML = \"Status:\";\n",
        "            labelElement = document.createElement('span');\n",
        "            labelElement.innerText = 'No data';\n",
        "            labelElement.style.fontWeight = 'bold';\n",
        "            modelOut.appendChild(labelElement);\n",
        "            div.appendChild(modelOut);\n",
        "\n",
        "            video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            video.width = div.clientWidth - 6;\n",
        "            video.setAttribute('playsinline', '');\n",
        "            video.onclick = () => { shutdown = true; };\n",
        "            stream = await navigator.mediaDevices.getUserMedia(\n",
        "                {video: { facingMode: \"environment\"}});\n",
        "            div.appendChild(video);\n",
        "\n",
        "            imgElement = document.createElement('img');\n",
        "            imgElement.style.position = 'absolute';\n",
        "            imgElement.style.zIndex = 1;\n",
        "            imgElement.onclick = () => { shutdown = true; };\n",
        "            div.appendChild(imgElement);\n",
        "\n",
        "            const instruction = document.createElement('div');\n",
        "            instruction.innerHTML =\n",
        "                '' +\n",
        "                '';\n",
        "            div.appendChild(instruction);\n",
        "            instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "            window.addEventListener('keydown', function(e) {\n",
        "                if (e.key === 's' || e.key === 'S') {\n",
        "                    shutdown = true;\n",
        "                }\n",
        "            });\n",
        "\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            captureCanvas = document.createElement('canvas');\n",
        "            captureCanvas.width = 640;\n",
        "            captureCanvas.height = 480;\n",
        "            window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "            return stream;\n",
        "        }\n",
        "\n",
        "        async function stream_frame(label, imgData) {\n",
        "            if (shutdown) {\n",
        "                removeDom();\n",
        "                shutdown = false;\n",
        "                return '';\n",
        "            }\n",
        "\n",
        "            var preCreate = Date.now();\n",
        "            stream = await createDom();\n",
        "\n",
        "            var preShow = Date.now();\n",
        "            if (label != \"\") {\n",
        "                labelElement.innerHTML = label;\n",
        "            }\n",
        "\n",
        "            if (imgData != \"\") {\n",
        "                var videoRect = video.getClientRects()[0];\n",
        "                imgElement.style.top = videoRect.top + \"px\";\n",
        "                imgElement.style.left = videoRect.left + \"px\";\n",
        "                imgElement.style.width = videoRect.width + \"px\";\n",
        "                imgElement.style.height = videoRect.height + \"px\";\n",
        "                imgElement.src = imgData;\n",
        "            }\n",
        "\n",
        "            var preCapture = Date.now();\n",
        "            var result = await new Promise(function(resolve, reject) {\n",
        "                pendingResolve = resolve;\n",
        "            });\n",
        "            shutdown = false;\n",
        "\n",
        "            return {'create': preShow - preCreate,\n",
        "                    'show': preCapture - preShow,\n",
        "                    'capture': Date.now() - preCapture,\n",
        "                    'img': result};\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "    data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "    return data\n",
        "\n",
        "video_stream()\n",
        "label_html = 'Capturing...'\n",
        "bbox = ''\n",
        "count = 0\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    bbox_array = np.zeros([480, 640, 3], dtype=np.uint8)\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "\n",
        "        face = img[y:y+h, x:x+w]\n",
        "        face_array = preprocess_face(face, target_shape=model.input_shape)\n",
        "\n",
        "        label_index, confidence = predict_label(face_array)\n",
        "\n",
        "        if confidence > 0.8:\n",
        "            label = f\"{class_labels[label_index]} ({confidence*100:.2f}%)\"\n",
        "            color = (0, 255, 0)\n",
        "        else:\n",
        "            label = \"Unknown\"\n",
        "            color = (0, 0, 255)\n",
        "\n",
        "        cv2.rectangle(bbox_array, (x, y), (x+w, y+h), color, 2)\n",
        "        cv2.putText(bbox_array, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
        "\n",
        "    bbox_array = cv2.cvtColor(bbox_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    alpha_channel = np.full(bbox_array.shape[:2], 128, dtype=np.uint8)\n",
        "\n",
        "    bbox_array_with_alpha = np.dstack([bbox_array, alpha_channel])\n",
        "\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array_with_alpha)\n",
        "\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "id": "LcXd3QtuPGcy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "96bee72d-fc97-456c-9673-bd72b368fed4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Class Labels: {0: 'Faysal', 1: 'Mohim', 2: 'Tanzil', 3: 'Tareq'}\n",
            "Loaded Labels: {0: 'Faysal', 1: 'Mohim', 2: 'Tanzil', 3: 'Tareq'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        var video;\n",
              "        var div = null;\n",
              "        var stream;\n",
              "        var captureCanvas;\n",
              "        var imgElement;\n",
              "        var labelElement;\n",
              "\n",
              "        var pendingResolve = null;\n",
              "        var shutdown = false;\n",
              "\n",
              "        function removeDom() {\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            video.remove();\n",
              "            div.remove();\n",
              "            video = null;\n",
              "            div = null;\n",
              "            stream = null;\n",
              "            imgElement = null;\n",
              "            captureCanvas = null;\n",
              "            labelElement = null;\n",
              "        }\n",
              "\n",
              "        function onAnimationFrame() {\n",
              "            if (!shutdown) {\n",
              "                window.requestAnimationFrame(onAnimationFrame);\n",
              "            }\n",
              "            if (pendingResolve) {\n",
              "                var result = \"\";\n",
              "                if (!shutdown) {\n",
              "                    captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "                    result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
              "                }\n",
              "                var lp = pendingResolve;\n",
              "                pendingResolve = null;\n",
              "                lp(result);\n",
              "            }\n",
              "        }\n",
              "\n",
              "        async function createDom() {\n",
              "            if (div !== null) {\n",
              "                return stream;\n",
              "            }\n",
              "\n",
              "            div = document.createElement('div');\n",
              "            div.style.border = '2px solid black';\n",
              "            div.style.padding = '3px';\n",
              "            div.style.width = '100%';\n",
              "            div.style.height = '100%';\n",
              "            div.style.maxWidth = '600px';\n",
              "            document.body.appendChild(div);\n",
              "\n",
              "            const modelOut = document.createElement('div');\n",
              "            modelOut.innerHTML = \"Status:\";\n",
              "            labelElement = document.createElement('span');\n",
              "            labelElement.innerText = 'No data';\n",
              "            labelElement.style.fontWeight = 'bold';\n",
              "            modelOut.appendChild(labelElement);\n",
              "            div.appendChild(modelOut);\n",
              "\n",
              "            video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            video.width = div.clientWidth - 6;\n",
              "            video.setAttribute('playsinline', '');\n",
              "            video.onclick = () => { shutdown = true; };\n",
              "            stream = await navigator.mediaDevices.getUserMedia(\n",
              "                {video: { facingMode: \"environment\"}});\n",
              "            div.appendChild(video);\n",
              "\n",
              "            imgElement = document.createElement('img');\n",
              "            imgElement.style.position = 'absolute';\n",
              "            imgElement.style.zIndex = 1;\n",
              "            imgElement.onclick = () => { shutdown = true; };\n",
              "            div.appendChild(imgElement);\n",
              "\n",
              "            const instruction = document.createElement('div');\n",
              "            instruction.innerHTML =\n",
              "                '' +\n",
              "                '';\n",
              "            div.appendChild(instruction);\n",
              "            instruction.onclick = () => { shutdown = true; };\n",
              "\n",
              "            // Add key press event listener\n",
              "            window.addEventListener('keydown', function(e) {\n",
              "                if (e.key === 's' || e.key === 'S') {\n",
              "                    shutdown = true;  // Stop the video stream on 'S' key press\n",
              "                }\n",
              "            });\n",
              "\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            captureCanvas = document.createElement('canvas');\n",
              "            captureCanvas.width = 640;\n",
              "            captureCanvas.height = 480;\n",
              "            window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "            return stream;\n",
              "        }\n",
              "\n",
              "        async function stream_frame(label, imgData) {\n",
              "            if (shutdown) {\n",
              "                removeDom();\n",
              "                shutdown = false;\n",
              "                return '';\n",
              "            }\n",
              "\n",
              "            var preCreate = Date.now();\n",
              "            stream = await createDom();\n",
              "\n",
              "            var preShow = Date.now();\n",
              "            if (label != \"\") {\n",
              "                labelElement.innerHTML = label;\n",
              "            }\n",
              "\n",
              "            if (imgData != \"\") {\n",
              "                var videoRect = video.getClientRects()[0];\n",
              "                imgElement.style.top = videoRect.top + \"px\";\n",
              "                imgElement.style.left = videoRect.left + \"px\";\n",
              "                imgElement.style.width = videoRect.width + \"px\";\n",
              "                imgElement.style.height = videoRect.height + \"px\";\n",
              "                imgElement.src = imgData;\n",
              "            }\n",
              "\n",
              "            var preCapture = Date.now();\n",
              "            var result = await new Promise(function(resolve, reject) {\n",
              "                pendingResolve = resolve;\n",
              "            });\n",
              "            shutdown = false;\n",
              "\n",
              "            return {'create': preShow - preCreate,\n",
              "                    'show': preCapture - preShow,\n",
              "                    'capture': Date.now() - preCapture,\n",
              "                    'img': result};\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}